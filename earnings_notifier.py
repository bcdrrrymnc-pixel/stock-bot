"""
æ±ºç®—ãƒ»ãƒ‹ãƒ¥ãƒ¼ã‚¹ Discordé€šçŸ¥Bot
- TDnet RSSãƒ•ã‚£ãƒ¼ãƒ‰ã§æ±ºç®—çŸ­ä¿¡ã‚’ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ å–å¾—
- EDINET APIã§æ¥­ç¸¾ä¿®æ­£ãƒ»è–¬äº‹æ‰¿èªã‚’è£œå®Œ
- yfinanceã§è²¡å‹™ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
"""

import os
import json
import time
import requests
import yfinance as yf
import xml.etree.ElementTree as ET
from collections import Counter
from datetime import datetime, date, timedelta
from pathlib import Path

DISCORD_EARNINGS_WEBHOOK = os.environ["DISCORD_EARNINGS_WEBHOOK"]
DISCORD_NEWS_WEBHOOK     = os.environ["DISCORD_NEWS_WEBHOOK"]
EDINET_API_KEY           = os.environ.get("EDINET_API_KEY", "")

SENT_FILE   = Path("sent_ids.json")
EDINET_BASE = "https://api.edinet-fsa.go.jp/api/v2"

# TDnet RSSãƒ•ã‚£ãƒ¼ãƒ‰ï¼ˆæ±è¨¼é©æ™‚é–‹ç¤º å…¨ä»¶ï¼‰
TDNET_RSS_URLS = [
    "https://www.release.tdnet.info/inbs/RSS_I_main_00.xml",   # å½“æ—¥å…¨ä»¶
    "https://www.release.tdnet.info/inbs/RSS_I_main_01.xml",   # å‰æ—¥
]

EDINET_SKIP = [
    "æœ‰ä¾¡è¨¼åˆ¸å ±å‘Šæ›¸", "å››åŠæœŸå ±å‘Šæ›¸", "åŠæœŸå ±å‘Šæ›¸",
    "è‡¨æ™‚å ±å‘Šæ›¸", "å†…éƒ¨çµ±åˆ¶å ±å‘Šæ›¸", "å¤§é‡ä¿æœ‰å ±å‘Šæ›¸",
    "å¤‰æ›´å ±å‘Šæ›¸", "å…¬é–‹è²·ä»˜", "è¨‚æ­£", "æœ‰ä¾¡è¨¼åˆ¸å±Šå‡ºæ›¸",
]

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# é€ä¿¡æ¸ˆã¿IDç®¡ç†
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def load_sent() -> set:
    if SENT_FILE.exists():
        data = json.loads(SENT_FILE.read_text(encoding="utf-8"))
        return set(data.get("ids", []))
    return set()

def save_sent(sent: set):
    ids = list(sent)[-3000:]
    SENT_FILE.write_text(json.dumps({"ids": ids}, ensure_ascii=False, indent=2), encoding="utf-8")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# TDnet RSSå–å¾—
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def fetch_tdnet_rss() -> list[dict]:
    results = []
    headers = {"User-Agent": "Mozilla/5.0 (compatible; StockBot/1.0)"}

    for rss_url in TDNET_RSS_URLS:
        try:
            r = requests.get(rss_url, headers=headers, timeout=30)
            print(f"[TDnet RSS] {rss_url} â†’ {r.status_code}")

            if r.status_code != 200:
                continue

            # ãƒ‡ãƒãƒƒã‚°ï¼šå…ˆé ­200æ–‡å­—è¡¨ç¤º
            print(f"[TDnet RSS] å…ˆé ­: {r.text[:300]!r}")

            root = ET.fromstring(r.content)
            ns   = {"": root.tag.split("}")[0].strip("{")} if "}" in root.tag else {}

            # RSS 2.0 å½¢å¼
            items = root.findall(".//item")
            print(f"[TDnet RSS] itemæ•°: {len(items)}")

            for item in items:
                def txt(tag):
                    el = item.find(tag)
                    return el.text.strip() if el is not None and el.text else ""

                title   = txt("title")
                link    = txt("link")
                pubdate = txt("pubDate")
                desc    = txt("description")

                # descriptionã‹ã‚‰tickerãƒ»ä¼šç¤¾åã‚’æŠ½å‡º
                # å½¢å¼ä¾‹: "7203 ãƒˆãƒ¨ã‚¿è‡ªå‹•è»Š"
                company = desc
                ticker  = ""
                parts   = desc.strip().split(" ", 1)
                if len(parts) == 2 and parts[0].isdigit() and len(parts[0]) == 4:
                    ticker  = parts[0]
                    company = parts[1]

                doc_id = link.split("=")[-1] if "=" in link else f"rss_{title[:30]}"

                results.append({
                    "id":      doc_id,
                    "company": company,
                    "ticker":  ticker,
                    "title":   title,
                    "time":    pubdate,
                    "url":     link,
                    "source":  "tdnet",
                })

        except Exception as e:
            print(f"[TDnet RSS] ã‚¨ãƒ©ãƒ¼ ({rss_url}): {e}")

    print(f"[TDnet RSS] åˆè¨ˆ: {len(results)}ä»¶")
    if results:
        print(f"[TDnet RSS] ã‚µãƒ³ãƒ—ãƒ«: {results[0]}")
    return results

def classify_tdnet(item: dict) -> str | None:
    title = item.get("title", "")
    if any(kw in title for kw in ["æ±ºç®—çŸ­ä¿¡", "å››åŠæœŸæ±ºç®—çŸ­ä¿¡", "ä¸­é–“æ±ºç®—çŸ­ä¿¡"]):
        return "earnings"
    if any(kw in title for kw in ["ä¸Šæ–¹ä¿®æ­£", "ä¸‹æ–¹ä¿®æ­£", "æ¥­ç¸¾ä¿®æ­£", "æ¥­ç¸¾äºˆæƒ³ã®ä¿®æ­£"]):
        return "revision"
    if any(kw in title for kw in ["è–¬äº‹", "FDA", "æ²»é¨“", "æ–°è–¬", "æ‰¿èªå–å¾—", "è£½é€ è²©å£²æ‰¿èª"]):
        return "pharma"
    return None

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# EDINETï¼ˆæ¥­ç¸¾ä¿®æ­£ãƒ»è–¬äº‹æ‰¿èªã®è£œå®Œï¼‰
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def edinet_headers() -> dict:
    return {"Ocp-Apim-Subscription-Key": EDINET_API_KEY} if EDINET_API_KEY else {}

def fetch_edinet_documents(target_date: str) -> list[dict]:
    url = f"{EDINET_BASE}/documents.json"
    params = {"date": target_date, "type": 2 if EDINET_API_KEY else 1}
    try:
        r = requests.get(url, params=params, headers=edinet_headers(), timeout=30)
        r.raise_for_status()
        results = r.json().get("results", [])
        print(f"[EDINET] {target_date} â†’ {len(results)}ä»¶")
        return results
    except Exception as e:
        print(f"[EDINET] ã‚¨ãƒ©ãƒ¼: {e}")
        return []

def classify_edinet(doc: dict) -> str | None:
    desc = doc.get("docDescription", "")
    if any(kw in desc for kw in EDINET_SKIP):
        return None
    if any(kw in desc for kw in ["ä¸Šæ–¹ä¿®æ­£", "ä¸‹æ–¹ä¿®æ­£", "æ¥­ç¸¾ä¿®æ­£", "æ¥­ç¸¾äºˆæƒ³ã®ä¿®æ­£"]):
        return "revision"
    if any(kw in desc for kw in ["è–¬äº‹", "FDA", "æ²»é¨“", "æ–°è–¬", "æ‰¿èªå–å¾—", "è£½é€ è²©å£²æ‰¿èª"]):
        return "pharma"
    return None

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# yfinance
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def get_financials(ticker_jp: str) -> dict:
    if not ticker_jp or not ticker_jp.isdigit():
        return {}
    try:
        tk   = yf.Ticker(f"{ticker_jp}.T")
        info = tk.info
        fin  = tk.financials
        revenue = net_income = None
        if not fin.empty:
            rev_key = [k for k in fin.index if "Revenue" in k]
            inc_key = [k for k in fin.index if "Net Income" in k]
            if rev_key: revenue    = fin.loc[rev_key[0]].iloc[0]
            if inc_key: net_income = fin.loc[inc_key[0]].iloc[0]
        return {
            "company":    info.get("longName") or info.get("shortName", ""),
            "sector":     info.get("sector", ""),
            "revenue":    revenue,
            "net_income": net_income,
            "total_debt": info.get("totalDebt"),
        }
    except Exception as e:
        print(f"[yfinance] {ticker_jp} ã‚¨ãƒ©ãƒ¼: {e}")
        return {}

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def fmt_yen(value) -> str:
    if value is None: return "N/A"
    v = float(value)
    if abs(v) >= 1e12: return f"{v/1e12:.2f}å…†å††"
    if abs(v) >= 1e8:  return f"{v/1e8:.1f}å„„å††"
    return f"{v/1e4:.0f}ä¸‡å††"

def build_earnings_embed(item: dict, fin: dict) -> dict:
    ticker  = item.get("ticker", "").strip()
    company = fin.get("company") or item.get("company", "ä¸æ˜")
    sector  = fin.get("sector") or "ä¸æ˜"
    heading = f"ğŸ“Š {company}" + (f"ï¼ˆ{ticker}ï¼‰" if ticker else "") + " æ±ºç®—ç™ºè¡¨"
    return {
        "username": "æ±ºç®—Bot",
        "embeds": [{
            "title": heading,
            "description": item.get("title", ""),
            "url": item.get("url", "https://www.release.tdnet.info"),
            "color": 0x00b4d8,
            "fields": [
                {"name": "ğŸ’¹ å£²ä¸Šé«˜",     "value": fmt_yen(fin.get("revenue")),    "inline": True},
                {"name": "ğŸ“ˆ ç´”åˆ©ç›Š",     "value": fmt_yen(fin.get("net_income")), "inline": True},
                {"name": "ğŸ¦ æœ‰åˆ©å­è² å‚µ", "value": fmt_yen(fin.get("total_debt")), "inline": True},
            ],
            "footer": {"text": f"ã‚»ã‚¯ã‚¿ãƒ¼: {sector} | TDnet"},
            "timestamp": datetime.utcnow().isoformat() + "Z",
        }]
    }

def build_news_embed(company, ticker, title, url, doc_type, source="TDnet") -> dict:
    type_map = {
        "revision": ("ğŸ”„ æ¥­ç¸¾ä¿®æ­£", 0xe63946 if "ä¸‹æ–¹" in title else 0x2dc653),
        "pharma":   ("ğŸ’Š æ–°è–¬ãƒ»è–¬äº‹æ‰¿èª", 0x9b5de5),
    }
    label, color = type_map.get(doc_type, ("ğŸ“Œ é–‹ç¤ºæƒ…å ±", 0xadb5bd))
    heading = f"{label}ï½œ{company}" + (f"ï¼ˆ{ticker}ï¼‰" if ticker else "")
    return {
        "username": "ãƒ‹ãƒ¥ãƒ¼ã‚¹Bot",
        "embeds": [{"title": heading, "description": title[:200], "url": url,
                    "color": color, "footer": {"text": source},
                    "timestamp": datetime.utcnow().isoformat() + "Z"}]
    }

def post_discord(webhook_url: str, payload: dict):
    if not webhook_url:
        print("[Discord] Webhook URLãŒç©ºã§ã™ã€‚")
        return
    r = requests.post(webhook_url, json=payload, timeout=15)
    if r.status_code == 429:
        time.sleep(int(r.headers.get("Retry-After", 5)))
        requests.post(webhook_url, json=payload, timeout=15)
    elif r.status_code not in (200, 204):
        print(f"[Discord] ã‚¨ãƒ©ãƒ¼ {r.status_code}: {r.text[:200]}")
    else:
        print("[Discord] é€ä¿¡æˆåŠŸ")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ãƒ¡ã‚¤ãƒ³
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def main():
    sent = load_sent()
    new_sent = 0
    print(f"[é€ä¿¡æ¸ˆã¿ID] {len(sent)}ä»¶ã‚’ãƒ­ãƒ¼ãƒ‰")

    # TDnet RSS
    for item in fetch_tdnet_rss():
        itype = classify_tdnet(item)
        if not itype: continue
        doc_id = f"tdnet_{item['id']}"
        if doc_id in sent: continue
        ticker = item.get("ticker", "").strip()
        if itype == "earnings":
            fin = get_financials(ticker) if ticker else {}
            post_discord(DISCORD_EARNINGS_WEBHOOK, build_earnings_embed(item, fin))
            print(f"[æ±ºç®—é€ä¿¡] {item['company']}ï¼ˆ{ticker}ï¼‰")
        else:
            post_discord(DISCORD_NEWS_WEBHOOK, build_news_embed(
                item["company"], ticker, item["title"], item["url"], itype))
            print(f"[ãƒ‹ãƒ¥ãƒ¼ã‚¹é€ä¿¡] {itype} / {item['company']}")
        sent.add(doc_id)
        new_sent += 1
        time.sleep(1)

    # EDINETè£œå®Œ
    edinet_docs = []
    for days_ago in range(3):
        target = (date.today() - timedelta(days=days_ago)).strftime("%Y-%m-%d")
        edinet_docs = fetch_edinet_documents(target)
        if edinet_docs: break
    for doc in edinet_docs:
        doc_id = f"edinet_{doc.get('docID','')}"
        if doc_id in sent: continue
        dtype = classify_edinet(doc)
        if not dtype: continue
        ticker = (doc.get("secCode") or "").strip()
        desc   = doc.get("docDescription", "")
        url    = f"https://disclosure2.edinet-fsa.go.jp/WZEK0040.aspx?S1{doc.get('docID','')}"
        post_discord(DISCORD_NEWS_WEBHOOK, build_news_embed(
            doc.get("filerName","ä¸æ˜"), ticker, desc, url, dtype, "EDINET"))
        print(f"[ãƒ‹ãƒ¥ãƒ¼ã‚¹é€ä¿¡EDINET] {dtype} / {doc.get('filerName')}")
        sent.add(doc_id)
        new_sent += 1
        time.sleep(1)

    save_sent(sent)
    print(f"å®Œäº†ã€‚æ–°è¦é€ä¿¡: {new_sent}ä»¶")

if __name__ == "__main__":
    main()
